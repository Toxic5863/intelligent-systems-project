{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn                                                # for neural networks and performance metrics\n",
    "import numpy as np                                            # for math and data operations\n",
    "import pandas as pd                                           # for dataframes used in documentation and debugging\n",
    "import random                                                 # for use in training data creation\n",
    "import math\n",
    "import string\n",
    "from threading import Thread\n",
    "import time\n",
    "from pyeasyga import pyeasyga\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [0. 1.]\n",
      " [0. 0.]\n",
      " [1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n"
     ]
    }
   ],
   "source": [
    "training_input_list = np.zeros((1000, 2))                           # creating a column vector for inputs. Determines training size of the rest of the data\n",
    "for i in range(training_input_list.shape[0]):                        # populating the input column vector via a for loop\n",
    "    training_input_list[i][0] = random.randint(0, 1)\n",
    "    training_input_list[i][1] = random.randint(0, 1)\n",
    "training_xor_list = np.zeros((training_input_list.shape[0],1))       # creating a column vector of sins for outputs\n",
    "for i in range(training_xor_list.shape[0]):                          # calculating the appropriate outputs for the input column vector\n",
    "    training_xor_list[i][0] = training_input_list[i][0] != training_input_list[i][1]      # as per the XOR logical operator\n",
    "\n",
    "    \n",
    "print(training_input_list[:10])           # this is just debug code to verify the shapes of the column vectors\n",
    "print(training_xor_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData = [training_input_list, training_xor_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a timed fitting function for neural networks to make sure candidate solutions are reasonably efficient\n",
    "def timedFit(ANN, data):\n",
    "    score = 0\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data[0], data[1], test_size=0.4)\n",
    "    fitting = Thread(target=ANN.fit(), args=(X_train, Y_train))\n",
    "    threading.join(fitting, timeout=5)\n",
    "    score = ANN.score(X_test, Y_test)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiating the genetic algorithms\n",
    "genetics = pyeasyga.GeneticAlgorithm(trainingData,\n",
    "                               population_size=100,\n",
    "                               generations=15,\n",
    "                               crossover_probability=0.80,\n",
    "                               mutation_probability=0.15,\n",
    "                               elitism=True,\n",
    "                               maximise_fitness=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the chromosomes' structure\n",
    "def create_individual(data):                               # Each genome is a half byte representing the size of a hidden layer,\n",
    "    individual = [random.randint(0, 1) for _ in range(20)]   # with each neural network having a maximum of 5 hidden layers\n",
    "    for i in range(len(individual)):\n",
    "        if not((i+1) % 4):\n",
    "            individual[i] = int(random.randint(0, int(i/4)) != 0) if not(individual[i]) else individual[i]\n",
    "    return individual\n",
    "# create_individual function overwrites the default to minimize the odds that bits starting genomes of hidden layers will be 0,\n",
    "# thereby reducing the odds of missing hidden layers in chromosomes of the initial population with minimal increase of bias to\n",
    "# deeper networks. Odds of a genome-starting bit being replaced with a 1 are highest for layers closest to the start of the\n",
    "# network, as the rest of the network construction throws out all layers right of a missing hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_genome(genome):     # Iterates through the list of bits of a genome and evaluates them as a binary number\n",
    "    value = \"0B\"\n",
    "    for bit in genome:\n",
    "        value += str(bit)\n",
    "    return int(value, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the fitness function\n",
    "def fitness(individual, data): #builds a neural network according to the genomes representing the architecture and tests\n",
    "    fitness = 0                # the neural network\n",
    "    genomes = [evaluate_genome(individual[0:4]),\n",
    "               evaluate_genome(individual[4:8]),\n",
    "               evaluate_genome(individual[8:12]),\n",
    "               evaluate_genome(individual[12:16]),\n",
    "               evaluate_genome(individual[16:20])]\n",
    "    \n",
    "    if genomes[0]:    # a series of checks to confirm that the shape represented by the genome is valid\n",
    "        if genomes[1]: # will only construct a neural network using valid genomes from the left end of the chromosome\n",
    "            if genomes[2]:\n",
    "                if genomes[3]:\n",
    "                    if genomes[4]:\n",
    "                        neuralNetwork = MLPClassifier(hidden_layer_sizes=(genomes[0], genomes[1], genomes[2], genomes[3], genomes[4]), activation='tanh', solver='lbfgs', max_iter=100)\n",
    "                    else:\n",
    "                        neuralNetwork = MLPClassifier(hidden_layer_sizes=(genomes[0], genomes[1], genomes[2], genomes[3]), activation='tanh', solver='lbfgs', max_iter=100)\n",
    "                else:\n",
    "                    neuralNetwork = MLPClassifier(hidden_layer_sizes=(genomes[0], genomes[1], genomes[2]), activation='tanh', solver='lbfgs', max_iter=100)\n",
    "            else:\n",
    "                neuralNetwork = MLPClassifier(hidden_layer_sizes=(genomes[0], genomes[1]), activation='tanh', solver='lbfgs', max_iter=100)\n",
    "        else:\n",
    "            neuralNetwork = MLPClassifier(hidden_layer_sizes=(genomes[0]), activation='tanh', solver='lbfgs', max_iter=100)\n",
    "    else:\n",
    "        return fitness\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data[0], data[1], test_size=0.4)\n",
    "    neuralNetwork.fit(X_train, np.ravel(Y_train))\n",
    "    return neuralNetwork.score(X_test, np.ravel(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "genetics.create_individual = create_individual\n",
    "genetics.fitness_function = fitness\n",
    "genetics.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, [1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(genetics.best_individual())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
