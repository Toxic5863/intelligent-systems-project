{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn                                                # for neural networks and performance metrics\n",
    "import numpy as np                                            # for math and data operations\n",
    "import pandas as pd                                           # for dataframes used in documentation and debugging\n",
    "import random                                                 # for use in training data creation\n",
    "import string                                                 # for converting the genomes to meaningful information\n",
    "from pyeasyga import pyeasyga                                 # the genetic algorithms library\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the chromosomes' structure\n",
    "def create_individual(data):                               # Each genome is a half byte representing the size of a hidden layer,\n",
    "    individual = [random.randint(0, 1) for _ in range(20)]   # with each neural network having a maximum of 5 hidden layers\n",
    "    for i in range(len(individual)):\n",
    "        if not((i+1) % 4):\n",
    "            individual[i] = int(random.randint(0, int(i/4)) != 0) if not(individual[i]) else individual[i]\n",
    "    return individual\n",
    "# create_individual function overwrites the default to minimize the odds that bits starting genomes of hidden layers will be 0,\n",
    "# thereby reducing the odds of missing hidden layers in chromosomes of the initial population with minimal increase of bias to\n",
    "# deeper networks. Odds of a genome-starting bit being replaced with a 1 are highest for layers closest to the start of the\n",
    "# network, as the rest of the network construction throws out all layers right of a missing hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_genome(genome):     # Iterates through the list of bits of a genome and evaluates them as a binary number\n",
    "    value = \"0B\"\n",
    "    for bit in genome:\n",
    "        value += str(bit)\n",
    "    return int(value, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the fitness function\n",
    "def fitness(individual, data): #builds a neural network according to the genomes representing the architecture and tests\n",
    "    fitness = 0                # the neural network\n",
    "    genomes = [evaluate_genome(individual[0:4]),\n",
    "               evaluate_genome(individual[4:8]),\n",
    "               evaluate_genome(individual[8:12]),\n",
    "               evaluate_genome(individual[12:16]),\n",
    "               evaluate_genome(individual[16:20])]\n",
    "    \n",
    "    if genomes[0]:    # a series of checks to confirm that the shape represented by the genome is valid\n",
    "        if genomes[1]: # will only construct a neural network using valid genomes from the left end of the chromosome\n",
    "            if genomes[2]:\n",
    "                if genomes[3]:\n",
    "                    if genomes[4]:\n",
    "                        neuralNetwork = MLPClassifier(hidden_layer_sizes=(genomes[0], genomes[1], genomes[2], genomes[3], genomes[4]), activation='tanh', solver='lbfgs', max_iter=100)\n",
    "                        propagationComplexity = genomes[0] * genomes[1] * genomes[2] * genomes[3] * genomes[4]\n",
    "                    else:\n",
    "                        neuralNetwork = MLPClassifier(hidden_layer_sizes=(genomes[0], genomes[1], genomes[2], genomes[3]), activation='tanh', solver='lbfgs', max_iter=100)\n",
    "                        propagationComplexity = genomes[0] * genomes[1] * genomes[2] * genomes[3]\n",
    "                else:\n",
    "                    neuralNetwork = MLPClassifier(hidden_layer_sizes=(genomes[0], genomes[1], genomes[2]), activation='tanh', solver='lbfgs', max_iter=100)\n",
    "                    propagationComplexity = genomes[0] * genomes[1] * genomes[2]\n",
    "            else:\n",
    "                neuralNetwork = MLPClassifier(hidden_layer_sizes=(genomes[0], genomes[1]), activation='tanh', solver='lbfgs', max_iter=100)\n",
    "                propagationComplexity = genomes[0] * genomes[1]\n",
    "        else:\n",
    "            neuralNetwork = MLPClassifier(hidden_layer_sizes=(genomes[0]), activation='tanh', solver='lbfgs', max_iter=100)\n",
    "            propagationComplexity = genomes[0]\n",
    "    else:\n",
    "        return fitness\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(data[0], data[1], test_size=0.4)\n",
    "    neuralNetwork.fit(X_train, np.ravel(Y_train))\n",
    "    accuracy = neuralNetwork.score(X_test, np.ravel(Y_test))\n",
    "    \n",
    "    return accuracy + (1 / propagationComplexity) if accuracy == 1.0 else accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def startGenetics(X, Y, initial_population=100, generations=200):\n",
    "    genetics = pyeasyga.GeneticAlgorithm([X, Y],  # It is the user's responsibility to provide clean and already-formatted\n",
    "                               population_size=initial_population,\n",
    "                               generations=generations,\n",
    "                               crossover_probability=0.00, # As the chromosomes are prioritized left to right, crossver along\n",
    "                               mutation_probability=0.13,  # this dimension does not provide significant use. An elitists\n",
    "                               elitism=True,               # approach with high initial population and mutation is used instead.\n",
    "                               maximise_fitness=True)\n",
    "    \n",
    "                               \n",
    "    genetics.create_individual = create_individual  # data. The genetic algorithm will not modify the training data in\n",
    "    genetics.fitness_function = fitness             # any way.\n",
    "    genetics.run()\n",
    "    solution = []\n",
    "    phenotype = [evaluate_genome(genetics.best_individual()[1][0:4]),\n",
    "            evaluate_genome(genetics.best_individual()[1][4:8]),\n",
    "            evaluate_genome(genetics.best_individual()[1][8:12]),       # generates the phenotype\n",
    "            evaluate_genome(genetics.best_individual()[1][12:16]),\n",
    "            evaluate_genome(genetics.best_individual()[1][16:20])]    \n",
    "    \n",
    "    for i in range(4):\n",
    "        if not(phenotype[i]):\n",
    "            break\n",
    "        solution.append(phenotype[i])           # adjusts the phenotype to a valid shape for an MLPClassifier object\n",
    "    return tuple(solution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
